{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dogs vs Cats Classification Using SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from libsvm.svmutil import *\n",
    "from libsvm.svm import *\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load training and test set\n",
    "y_train, X_train = svm_read_problem('./DogsVsCats/DogsVsCats.train')\n",
    "y_test, X_test = svm_read_problem('./DogsVsCats/DogsVsCats.test')\n",
    "\n",
    "# convert to numpy.ndarray\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Linear Kernel and Polynomial Kernel CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Linear SVM: 1/10\n",
      "Training Linear SVM Done: 1/10\n",
      "Testing Linear SVM: 1/10\n",
      "Accuracy = 59.84% (748/1250) (classification)\n",
      "Testing Linear SVM Done: 1/10\n",
      "Training Polynomial SVM: 1/10\n",
      "Training Polynomial SVM Done: 1/10\n",
      "Testing Polynomial SVM: 1/10\n",
      "Accuracy = 49.6% (620/1250) (classification)\n",
      "Testing Polynomial SVM Done: 1/10\n",
      "Training Linear SVM: 2/10\n",
      "Training Linear SVM Done: 2/10\n",
      "Testing Linear SVM: 2/10\n",
      "Accuracy = 57.76% (722/1250) (classification)\n",
      "Testing Linear SVM Done: 2/10\n",
      "Training Polynomial SVM: 2/10\n",
      "Training Polynomial SVM Done: 2/10\n",
      "Testing Polynomial SVM: 2/10\n",
      "Accuracy = 49.6% (620/1250) (classification)\n",
      "Testing Polynomial SVM Done: 2/10\n",
      "Training Linear SVM: 3/10\n",
      "Training Linear SVM Done: 3/10\n",
      "Testing Linear SVM: 3/10\n",
      "Accuracy = 61.28% (766/1250) (classification)\n",
      "Testing Linear SVM Done: 3/10\n",
      "Training Polynomial SVM: 3/10\n",
      "Training Polynomial SVM Done: 3/10\n",
      "Testing Polynomial SVM: 3/10\n",
      "Accuracy = 48.8% (610/1250) (classification)\n",
      "Testing Polynomial SVM Done: 3/10\n",
      "Training Linear SVM: 4/10\n",
      "Training Linear SVM Done: 4/10\n",
      "Testing Linear SVM: 4/10\n",
      "Accuracy = 59.76% (747/1250) (classification)\n",
      "Testing Linear SVM Done: 4/10\n",
      "Training Polynomial SVM: 4/10\n",
      "Training Polynomial SVM Done: 4/10\n",
      "Testing Polynomial SVM: 4/10\n",
      "Accuracy = 49.84% (623/1250) (classification)\n",
      "Testing Polynomial SVM Done: 4/10\n",
      "Training Linear SVM: 5/10\n",
      "Training Linear SVM Done: 5/10\n",
      "Testing Linear SVM: 5/10\n",
      "Accuracy = 60.32% (754/1250) (classification)\n",
      "Testing Linear SVM Done: 5/10\n",
      "Training Polynomial SVM: 5/10\n",
      "Training Polynomial SVM Done: 5/10\n",
      "Testing Polynomial SVM: 5/10\n",
      "Accuracy = 48.88% (611/1250) (classification)\n",
      "Testing Polynomial SVM Done: 5/10\n",
      "Training Linear SVM: 6/10\n",
      "Training Linear SVM Done: 6/10\n",
      "Testing Linear SVM: 6/10\n",
      "Accuracy = 60.48% (756/1250) (classification)\n",
      "Testing Linear SVM Done: 6/10\n",
      "Training Polynomial SVM: 6/10\n",
      "Training Polynomial SVM Done: 6/10\n",
      "Testing Polynomial SVM: 6/10\n",
      "Accuracy = 47.92% (599/1250) (classification)\n",
      "Testing Polynomial SVM Done: 6/10\n",
      "Training Linear SVM: 7/10\n",
      "Training Linear SVM Done: 7/10\n",
      "Testing Linear SVM: 7/10\n",
      "Accuracy = 61.6% (770/1250) (classification)\n",
      "Testing Linear SVM Done: 7/10\n",
      "Training Polynomial SVM: 7/10\n",
      "Training Polynomial SVM Done: 7/10\n",
      "Testing Polynomial SVM: 7/10\n",
      "Accuracy = 49.44% (618/1250) (classification)\n",
      "Testing Polynomial SVM Done: 7/10\n",
      "Training Linear SVM: 8/10\n",
      "Training Linear SVM Done: 8/10\n",
      "Testing Linear SVM: 8/10\n",
      "Accuracy = 58% (725/1250) (classification)\n",
      "Testing Linear SVM Done: 8/10\n",
      "Training Polynomial SVM: 8/10\n",
      "Training Polynomial SVM Done: 8/10\n",
      "Testing Polynomial SVM: 8/10\n",
      "Accuracy = 48.96% (612/1250) (classification)\n",
      "Testing Polynomial SVM Done: 8/10\n",
      "Training Linear SVM: 9/10\n",
      "Training Linear SVM Done: 9/10\n",
      "Testing Linear SVM: 9/10\n",
      "Accuracy = 61.12% (764/1250) (classification)\n",
      "Testing Linear SVM Done: 9/10\n",
      "Training Polynomial SVM: 9/10\n",
      "Training Polynomial SVM Done: 9/10\n",
      "Testing Polynomial SVM: 9/10\n",
      "Accuracy = 49.92% (624/1250) (classification)\n",
      "Testing Polynomial SVM Done: 9/10\n",
      "Training Linear SVM: 10/10\n",
      "Training Linear SVM Done: 10/10\n",
      "Testing Linear SVM: 10/10\n",
      "Accuracy = 58.48% (731/1250) (classification)\n",
      "Testing Linear SVM Done: 10/10\n",
      "Training Polynomial SVM: 10/10\n",
      "Training Polynomial SVM Done: 10/10\n",
      "Testing Polynomial SVM: 10/10\n",
      "Accuracy = 48.56% (607/1250) (classification)\n",
      "Testing Polynomial SVM Done: 10/10\n"
     ]
    }
   ],
   "source": [
    "linear_params = '-t 0 -b 0'  # linear SVM and use it for classification\n",
    "poly_params = '-t 1 -d 5 -b 0'  # polynomial SVM with degree of 5 and use it for classification\n",
    "\n",
    "# K-fold cross-validation\n",
    "kf = KFold(n_splits=10, shuffle=True)\n",
    "linear_val_accuracies = []; poly_val_accuracies = []\n",
    "iters = 1\n",
    "\n",
    "for train_idx, val_idx in kf.split(X_train):\n",
    "    \n",
    "    # split dataset\n",
    "    X_train_i, X_val_i = X_train[train_idx], X_train[val_idx]\n",
    "    y_train_i, y_val_i = y_train[train_idx], y_train[val_idx]\n",
    "    \n",
    "    # train linear SVM\n",
    "    print(\"Training Linear SVM: {}/{}\".format(iters, kf.get_n_splits(X_train)))\n",
    "    linear_model = svm_train(y_train_i, X_train_i, linear_params)\n",
    "    print(\"Training Linear SVM Done: {}/{}\".format(iters, kf.get_n_splits(X_train)))\n",
    "    \n",
    "    # validate linear SVM\n",
    "    print(\"Testing Linear SVM: {}/{}\".format(iters, kf.get_n_splits(X_train)))\n",
    "    _, val_acc, _ = svm_predict(y_val_i, X_val_i, linear_model)\n",
    "    linear_val_accuracies.append(val_acc[0])\n",
    "    print(\"Testing Linear SVM Done: {}/{}\".format(iters, kf.get_n_splits(X_train)))\n",
    "    \n",
    "    # train polynomial SVM\n",
    "    print(\"Training Polynomial SVM: {}/{}\".format(iters, kf.get_n_splits(X_train)))\n",
    "    poly_model = svm_train(y_train_i, X_train_i, poly_params)\n",
    "    print(\"Training Polynomial SVM Done: {}/{}\".format(iters, kf.get_n_splits(X_train)))\n",
    "    \n",
    "    # validate polynomial SVM\n",
    "    print(\"Testing Polynomial SVM: {}/{}\".format(iters, kf.get_n_splits(X_train)))\n",
    "    _, val_acc, _ = svm_predict(y_val_i, X_val_i, poly_model)\n",
    "    poly_val_accuracies.append(val_acc[0])\n",
    "    print(\"Testing Polynomial SVM Done: {}/{}\".format(iters, kf.get_n_splits(X_train)))\n",
    "    \n",
    "    iters += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Validation Accuracy of Linear SVM: 59.86 %\n",
      "Average Validation Accuracy of Polynomial SVM: 49.15 %\n"
     ]
    }
   ],
   "source": [
    "print(\"Average Validation Accuracy of Linear SVM: %.2f %%\" % (np.mean(linear_val_accuracies)))\n",
    "print(\"Average Validation Accuracy of Polynomial SVM: %.2f %%\" % (np.mean(poly_val_accuracies)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train Entire Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Linear SVM:\n",
      "Training Linear SVM Done\n",
      "Accuracy = 60.12% (7515/12500) (classification)\n",
      "Training Accuracy of Linear SVM: 60.12 %\n",
      "Testing Linear SVM\n",
      "Accuracy = 59.2% (7400/12500) (classification)\n",
      "Testing Linear SVM Done\n",
      "Test Accuracy of Linear SVM: 59.20 %\n"
     ]
    }
   ],
   "source": [
    "# Linear SVM\n",
    "\n",
    "# train\n",
    "print(\"Training Linear SVM:\")\n",
    "linear_model = svm_train(y_train, X_train, linear_params)\n",
    "print(\"Training Linear SVM Done\")\n",
    "_, train_acc, _ = svm_predict(y_train, X_train, linear_model)\n",
    "print(\"Training Accuracy of Linear SVM: %.2f %%\" % train_acc[0])\n",
    "\n",
    "# test\n",
    "print(\"Testing Linear SVM:\")\n",
    "_, test_acc, _ = svm_predict(y_test, X_test, linear_model)\n",
    "print(\"Testing Linear SVM Done\")\n",
    "print(\"Test Accuracy of Linear SVM: %.2f %%\" % test_acc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Polynomial SVM:\n",
      "Training Polynomial SVM Done\n",
      "Accuracy = 50.024% (6253/12500) (classification)\n",
      "Training Accuracy of Polynomial SVM: 50.02 %\n",
      "Testing Polynomial SVM\n",
      "Accuracy = 50.048% (6256/12500) (classification)\n",
      "Testing Polynomial SVM Done\n",
      "Test Accuracy of Polynomial SVM: 50.05 %\n"
     ]
    }
   ],
   "source": [
    "# Polynomial SVM\n",
    "\n",
    "# train\n",
    "print(\"Training Polynomial SVM:\")\n",
    "poly_model = svm_train(y_train, X_train, poly_params)\n",
    "print(\"Training Polynomial SVM Done\")\n",
    "_, train_acc, _ = svm_predict(y_train, X_train, poly_model)\n",
    "print(\"Training Accuracy of Polynomial SVM: %.2f %%\" % train_acc[0])\n",
    "\n",
    "# test\n",
    "print(\"Testing Polynomial SVM\")\n",
    "_, test_acc, _ = svm_predict(y_test, X_test, poly_model)\n",
    "print(\"Testing Polynomial SVM Done\")\n",
    "print(\"Test Accuracy of Polynomial SVM: %.2f %%\" % test_acc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Polynomial kernel has higher test accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy with Boosting Iterations of 10: 56.41 %\n"
     ]
    }
   ],
   "source": [
    "# K = 10\n",
    "adaboost = AdaBoostClassifier(base_estimator=SVC(probability=True, kernel='linear'), n_estimators=10)\n",
    "adaboost.fit(np.array([list(x.values()) for x in X_train]), y_train)\n",
    "y_pred = adaboost.predict([list(x.values()) for x in X_test])\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Test Accuracy with Boosting Iterations of 10: %.2f %%\" % (100*accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result show the accuracy of boosted SVM is lower than single SVM, which means the Adaboost SVM does not improve the performance. The main reason I reckon is SVM is a strong classifier, while Adaboost prefers multiple weak classifiers, so that is the reason why decision stump is used as default base estimator in AdaBoostClassifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy with Boosting Iterations of 20: 54.70 %\n"
     ]
    }
   ],
   "source": [
    "# K = 20\n",
    "adaboost = AdaBoostClassifier(base_estimator=SVC(probability=True, kernel='linear'), n_estimators=20)\n",
    "adaboost.fit(np.array([list(x.values()) for x in X_train]), y_train)\n",
    "y_pred = adaboost.predict([list(x.values()) for x in X_test])\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Test Accuracy with Boosting Iterations of 20: %.2f %%\" % (100*accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the number of boosting iterations increases to 20, the test accuracy is getting worse than K = 10. The reason is the same: Adaboost prefers to weak classifiers, but SVM is a strong classifier, so the performance will be even worse, even through we increase the number of boosting iterations. We compare the performance of Adaboost using SVM and decision stump as base estimator, respectively. We find the using decision stump is better than SVM, and with the increase of boosting iterations, the performance also improves. The results are shown below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy with Boosting Iterations of 10 Using Decision Stump: 62.73 %\n"
     ]
    }
   ],
   "source": [
    "# K = 10\n",
    "\n",
    "# Using decision stump as base estimator\n",
    "adaboost = AdaBoostClassifier(n_estimators=10)\n",
    "adaboost.fit(np.array([list(x.values()) for x in X_train]), y_train)\n",
    "y_pred = adaboost.predict([list(x.values()) for x in X_test])\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Test Accuracy with Boosting Iterations of 10 Using Decision Stump: %.2f %%\" % (100*accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy with Boosting Iterations of 20 Using Decision Stump: 64.42 %\n"
     ]
    }
   ],
   "source": [
    "# K = 20\n",
    "\n",
    "# Using decision stump as base estimator\n",
    "adaboost = AdaBoostClassifier(n_estimators=20)\n",
    "adaboost.fit(np.array([list(x.values()) for x in X_train]), y_train)\n",
    "y_pred = adaboost.predict([list(x.values()) for x in X_test])\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Test Accuracy with Boosting Iterations of 20 Using Decision Stump: %.2f %%\" % (100*accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our experiment, we did cross validation for model selection between linear SVM and polynomial SVM, and the results show that the averaged test accuracy of linear SVM is 60.12%, which outperforms polynomial SVM. Thus, we choosed polynomial SVM as base classifier to do Adaboost. However, the boosted result is not what we expected that boosted accuracy will be larger than non-boosted accuracy. The underlying reason is we need to choose weak classifier as our base estimator, and we also did an ablation study where we compared the performace of Adaboost with the same hyperparameters but using decision stump as base estimator. The result confirmed that using weak classifiers would increase the overall performance, and if we increase the number of boosting iterations, the test accuracy will also increase."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
